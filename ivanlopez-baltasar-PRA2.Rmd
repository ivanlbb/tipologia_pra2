---
title: 'Tipología y ciclo de vida de los datos: PRA2'
author: "Autor: Iván López-Baltasar Benito | David Quiles Gómez"
date: "Junio 2019"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
******
# Introducción
******
## Presentación

En esta actividad se elabora un caso práctico, consistente en el tratamiento de un conjunto de datos (en inglés, dataset), orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas.


## Objetivos

* Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.  
* Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.  
* Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.
* Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.  
* Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.  
* Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.  
* Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.
 
## Competencias
* Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.
* Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis  

## Descripcion del dataset 
En ésta práctica vamos a trabajar con el juego de datos de https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/ el cual contiene dos datasets, uno de vinos blancos y otro de vinos tintos. 

Ambos datasets contienen 11 atributos de entrada, correspondientes a pruebas fisioquímicas, y uno de salida: "quality". 

El objetivo del análisis será por un lado construir un modelo que nos pueda predecir la calidad de un vino, y por otro, construir un modelo que nos permita clasificar un vino en un determinado tipo (blanco/tinto).


******
# Carga y limpieza del dataset
******

Cargamos los paquetes R que vamos a usar
```{r message= FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
```

```{r message= FALSE, warning=FALSE}
blanco<-read.csv("vinos/winequality-white.csv", header=T, sep=";")
tinto<-read.csv("vinos/winequality-red.csv", header=T, sep=";")

```

Vamos a añadirle la clase a cada juego de datos para después unir ambos datasets.
```{r message= FALSE, warning=FALSE}
blanco$tipo<-'B'
tinto$tipo<-'T'

nomCols <- c("acidez_fija", "acidez_volatil", "acido_citrico", "azucar_residual", "cloruros","diox_azufre_libre","diox_azufre_total","densidad","pH","sulfatos", "alcohol","calidad", "tipo")

colnames(blanco) <- nomCols
colnames(tinto) <- nomCols

#str(blanco)
summary(blanco)
#str(tinto)
summary(tinto)
```

Ahora unimos ambos datasets
```{r message= FALSE, warning=FALSE}
# Unimos los dos juetos de datos en uno solo
totalData <- bind_rows(blanco,tinto)
filas=dim(totalData)[1]

# Factorizamos la variable tipo
totalData$tipo <- as.factor(totalData$tipo)

str(totalData)
summary(totalData)
```

## Nulos y/o elementos vacíos
Comprobamos que no haya valores vacíos o nulos.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Estadíssticas de valores vacios
colSums(is.na(totalData))
colSums(totalData=="")
```
## Valores extremos

En el resumen descriptivo pudimos observar tanto en el grupo vinos tintos como en el de blancos, los valores máximos de dioxido de azufre total parecen muy distantes de sus medidas de tencencia central. Vamos a identificarlos de manera gráfica con un diagrama box plot.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# comprobamos outliers en dioxido de azufre total en los blancos
#ggplot(totalData, aes(x=tipo, y=diox_azufre_total)) +  geom_point(size=2, shape=23)
datos.bp <-boxplot(blanco$diox_azufre_total, main="Blancos - Dioxido azufre total", horizontal = T)
```


```{r echo=TRUE, message=FALSE, warning=FALSE}
# comprobamos outliers en dioxido de azufre total en los tintos
datos.bp <-boxplot(tinto$diox_azufre_total, main="Tintos - Dioxido azufre total", horizontal = T)
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
boxplot.stats(blanco$diox_azufre_total)$out
boxplot.stats(tinto$diox_azufre_total)$out
```

Vemos que el sistema detecta 20 valores atípicos en los vinos blancos y 56 en los tintos. No tenemos un conocimiento suficiente para valorar si se han producido por errores o por diferentes metodologías de medición o si por el contrario, son valores correctos por lo que vamos solamente vamos a sacar de la muestra los que están más alejados del rango intercuartílico. 

De la muestra total sacamos el que tiene un valor > 400 y es blanco y de la de tintos los dos que tienen un valor superior a 250.

```{r echo=TRUE, message=FALSE, warning=FALSE}
blanco <-subset(blanco, diox_azufre_total<400)
tinto <- subset(tinto, diox_azufre_total<250)
totalData <- bind_rows(blanco,tinto)
filas=dim(totalData)[1]
# Factorizamos la variable tipo
totalData$tipo <- as.factor(totalData$tipo)


#☺totalData <- subset(totalData, (tipo=="B"& diox_azufre_total < 400) | (tipo == "T" & diox_azufre_total < 250))
ggplot(totalData, aes(x=tipo, y=diox_azufre_total)) +  geom_point(size=2, shape=23)
```


# Análisis de los datos

A continuación vamos a realizar un análisis descriptivo de la  variable calidad.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(totalData$calidad)
#desviacion estandara
sd(totalData$calidad)

# mostramos un histograma de la calidad
ggplot(data = totalData[1:filas,],aes(x=calidad))+geom_histogram()+ geom_density(alpha=.2, fill="#FF6666") 

# Relacion entre calidad y tipo de vino
ggplot(data=totalData[1:filas,],aes(x=calidad,fill=tipo))+geom_bar()

# Grafico de frecuencias
ggplot(data = totalData[1:filas,],aes(x=calidad,fill=tipo))+geom_bar(position="fill")+ylab("Frecuencia")
```

Se puede deducir de los gráficos que los vinos blancos de la muestra tienen más calidad que los tintos.  



## Análisis de la normalidad y homogeneidad de la varianza


Vamos a comprobar la normalidad de la calidad en ambos grupos de vinos. Utilizaremos los tests de **Kolmogorov-Smirnov** y **Shapiro-Wilk**

```{r message= FALSE, warning=FALSE}
##
ks.test(tinto$calidad, pnorm, mean(tinto$calidad), sd(tinto$calidad))
shapiro.test(tinto$calidad)

ks.test(blanco$calidad, pnorm, mean(blanco$calidad), sd(blanco$calidad))
shapiro.test(blanco$calidad)

```
En ambos test se rechaza la hipótesis nula, por tanto consideramos que la calidad no se distribuye mediante una distribución normal en ninguno de los dos grupos. No obstante, por el **teorema central del límite** se podría considerar que los datos siguen una distribución normal.


Analizaremos la homocedasticidad de la varianza mediante el **test de Flinger-Killen** en cuanto a los grupos conformados por los vinos tintos y los blancos.  

```{r message= FALSE, warning=FALSE}
##
b <- blanco$calidad
t <- tinto$calidad
fligner.test(calidad ~ tipo, data= totalData)
```
Dado que el p-valor es > 0.05 podemos aceptar la hipóstesis nula de que las varianzas de ambas muestras son homogéneas.

# Pruebas estadísticas

## ¿Que tipo de vino tiene más calidad?

En los histogramas y gráficos de frecuencias pudimos observar que la calidad de los vinos blancos de la muestra era más alta que la de los tintos, vamos a realizar un contraste de hipótesis para comprobar si tenemos diferencias estadísticamente significativas en la media de la calidad de ambos grupos de vinos.

Considerando el análisis de la normalidad y homogeneidad de la varianza del punto anterior, aplicaremos la prueba **t de Student** formulando las siguientes hipótesis: 

      H0: nuB - nuT = 0
      H1: nuB - nuT > 0

donde nuB es la media muestral de la calidad de los vinos blancos y nuT es la media muestral de la calidad de los vinos tintos.

```{r message= FALSE, warning=FALSE}
## Realizamos el test por tipo de vino
t.test(calidad ~ tipo, data = totalData, alternative="greater")

```
Dado que el p-valor es inferior al nivel de significancia (0.05), debemos rechazar la hipótesis nula, por tanto podemos concluir que efectivamente, la calidad de los vinos blancos es superior que la de los vinos tintos de la muestra.


## ¿Qué prueba fisioquímica es más determinante para la calidad de un vino?

Vamos a calcular la matriz de correlaciones de las variables cuantitativas de cada grupo de vinos.  

```{r message= FALSE, warning=FALSE}
round(cor(blanco[,-13]),2)

```
Observando la matriz de correlaciones vemos que las variables dioxido de azufre libre y ácido cítrico, no tienen prácticamente ninguna correlación con la calidad, podríamos sacarlas del modelo. Por el contrario, el alcohol y la densidad son las variables que más correlación tienen con la calidad, positiva y negativa respectivamente, aunque la correlación es más bien baja.

Probamos la significancia de la correlación entre la calidad y el alcohol:

     Hipótesis nula H0: no hay relación
     Hipótesis alternativa H1: hay relación.

```{r message= FALSE, warning=FALSE}
cor.test(blanco$alcohol, blanco$calidad, method="pearson")
```

Comprobamos que el test nos arroja un p-value inferior a 0.05 por lo que rechazamos la hipótesis nula.

Comprobamos que para la densidad también rechazamos la hipótesis nula.

```{r message= FALSE, warning=FALSE}
cor.test(blanco$densidad, blanco$calidad, method="pearson")

```


Obtenemos la matriz de correlaciones para el grupo de vinos tinto  

```{r message= FALSE, warning=FALSE}

round(cor(tinto[,-13]),2)

```

Tampoco obtenemos unas correlaciones altas de la calidad con el resto de variables, por lo que consideramos que un modelo de regresión lineal no va a ser de mucha utilidad para predecir la calidad de los vinos.

## Regresion lineal

Partiendo del dataset de vinos blancos, vamos a hacer un análisis de regresión para estimar la calidad del vino.
Nos quedamos solamente con el dataset de vinos blancos y le quitamos la variable de tipo.  
```{r message= FALSE, warning=FALSE}
blancoQ <- blanco[,1:12]
str(blancoQ)
```
Vamos a dividir las observaciones en dos grupos, uno de entrenamiento para ajustar el modelo (2/3 de los datos) y uno de test (1/3 de los datos)  

```{r message= FALSE, warning=FALSE}
library(rminer)
set.seed(123)
h <- holdout(blancoQ$calidad,ratio=2/3,mode="stratified")
training <- blancoQ[h$tr,]
test <- blancoQ[h$ts,]
str(training)
str(test)
#training <- sample_frac(blancoQ, .7)
#test <- setdiff(blancoQ, training)

modelo <- lm(calidad ~ ., data = training)
summary(modelo)
```

Vemos que el valor R2 ajustado es bajo, 0.2797 por lo que el modelo no es capaz de predecir con precisión la calidad.

Vamos a verificarlo calculando la MSE

```{r message= FALSE, warning=FALSE}
# funcion que calcula la media de los cuadrados de las desviaciones 
dm <- function(actual, predicted){
  mean((actual - predicted)^2)
}

# MSE empleando las observaciones de entrenamiento
training_mse <- dm(modelo$fitted.values, training$calidad)
training_mse

# MSE empleando nuevas observaciones
predicciones <- predict(modelo, newdata = test)
test_mse <- dm(predicciones, test$calidad)
test_mse

```


## Modelo supervisado

### Clasificación. Random forest

A continuación vamos a aplicar un método de clasificación random forest mediante una validación cruzada con 4 folds para clasificar los vinos en tintos o blancos.

```{r message= FALSE, warning=FALSE}
library(caret)


h <- holdout(totalData$tipo,ratio=2/3,mode="stratified")
vino_entrenamiento <- totalData[h$tr,]
vino_prueba <- totalData[h$ts,]

train_control <-trainControl(method = "cv", number = 4)
mod<-train(tipo~., data=vino_entrenamiento, method="rf",trControl=train_control)
pred <- predict(mod, newdata=vino_prueba)
```

Obtenemos la matriz de confusión para comprobar la bondad del modelo.  
```{r message= FALSE, warning=FALSE}
confusionMatrix(pred,vino_prueba$tipo, positive="T")
```

Vemos que el resultado es excelente, el modelo nos clasifica los vinos con una precisión del 99.45% con un índice **kappa=0.985**   que nos indica que nuestra clasificación es un 98.5% mejor que una clasificación aleatoria.  

# Conclusiones